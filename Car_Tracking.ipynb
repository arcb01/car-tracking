{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch"
      ],
      "metadata": {
        "id": "9bWOdVaqPAcT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load video and its frames"
      ],
      "metadata": {
        "id": "F_ICVg1wOEyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/output7.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "total_frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oABXocjANpi-",
        "outputId": "195f9020-b543-46aa-fc01-f67c64713b3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7288"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO model load"
      ],
      "metadata": {
        "id": "FYiNWoTb0WVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# PyTorch Hub Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
        "model.classes = [2,3,5,7]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9drlPbn0YPY",
        "outputId": "06c276eb-9efe-4f91-d2e3-845e829eb3ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2022-10-21 Python-3.7.15 torch-1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect cars in each frame"
      ],
      "metadata": {
        "id": "TpNdHgudOwSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "sample_rate = 1\n",
        "i = 0\n",
        "t0 = time.time()\n",
        "for fno in range(0, total_frames/10, sample_rate):\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, fno)\n",
        "    _, image = cap.read()\n",
        "    image.shape\n",
        "    result = model(image)\n",
        "    # resultPd = result.pandas().xyxy[0]\n",
        "    # resultPd[\"frame\"] = 1\n",
        "    i+=1\n",
        "\n",
        "print(f\"total time: {time.time()-t0}\")\n",
        "print(f\"total frames: {i}\")\n"
      ],
      "metadata": {
        "id": "gvhrJN-T1m3r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "bbac7968-689f-4cf4-f2de-0d24846f5c71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b9c0cfd24674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfno\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultPd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqq-eX1GPuz8",
        "outputId": "84b479cc-22d8-40f8-e6e7-ea396197a407"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         xmin        ymin        xmax        ymax  confidence  class name  \\\n",
            "0  426.733246  498.594360  526.508850  579.966064    0.880898      2  car   \n",
            "1  407.039154  447.868774  502.197235  533.245178    0.856282      2  car   \n",
            "2  321.678131  300.121765  395.638458  351.660828    0.837218      2  car   \n",
            "3  183.938324  335.682465  212.680847  352.964905    0.392495      2  car   \n",
            "\n",
            "   frame  \n",
            "0      1  \n",
            "1      1  \n",
            "2      1  \n",
            "3      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "At7x_p_qSWkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}